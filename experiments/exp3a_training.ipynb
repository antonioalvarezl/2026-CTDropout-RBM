{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3a \u2014 Training with RBM (\u00a75.3)\n",
    "\n",
    "Both layers are trainable. Each rNODE realisation uses a **fixed** batch\n",
    "schedule (structured pruning). Predictions are ensemble-averaged over K\n",
    "realisations.\n",
    "\n",
    "**Contents:** Reference NODE, RBM ensemble, decision boundaries, benchmarks."
   ],
   "id": "ec6b18bb"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, sys, random\n",
    "\n",
    "for _root in (os.getcwd(), os.path.abspath(os.path.join(os.getcwd(), \"..\"))):\n",
    "    if os.path.isdir(os.path.join(_root, \"rnode\")) and _root not in sys.path:\n",
    "        sys.path.insert(0, _root)\n",
    "        break\n",
    "\n",
    "import torch, numpy as np\n",
    "from rnode.models import TimeDepODE_ELU\n",
    "from rnode.data import make_circles_data\n",
    "from rnode.utils import compute_accuracy\n",
    "from torchdiffeq import odeint"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "52c64b80"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ],
   "id": "4de9ac2b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "QUICK = False\n",
    "\n",
    "CFG = dict(\n",
    "    hidden_dim=24, T=2.0, seed=42,\n",
    "    n_train_steps=20, n_eval_steps=500,\n",
    "    alpha=0.01, beta=0.5,\n",
    "    n_epochs=1000 if not QUICK else 200,\n",
    "    lr=1e-3,\n",
    "    # RBM ensemble\n",
    "    n_batches=3,\n",
    "    n_realizations=10 if not QUICK else 3,\n",
    "    # Decision boundaries\n",
    "    n_grid=150, h_reps=[1, 2, 3],\n",
    "    n_real_boundary=20 if not QUICK else 5,\n",
    "    # Benchmarks\n",
    "    batch_configs=[2, 3, 4, 6],\n",
    "    n_benchmark_trials=5 if not QUICK else 2,\n",
    "    n_realizations_bench=10 if not QUICK else 3,\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "OUT = os.path.join(os.getcwd(), \"outputs\")\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "t_train = torch.linspace(0, CFG[\"T\"], CFG[\"n_train_steps\"])\n",
    "t_eval = torch.linspace(0, CFG[\"T\"], CFG[\"n_eval_steps\"])\n",
    "step_eval = float(CFG[\"T\"]) / (CFG[\"n_eval_steps\"] - 1)"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "94d309d3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ],
   "id": "3572521d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, y_train = make_circles_data(100, seed=42)\n",
    "X_test, y_test = make_circles_data(200, seed=123)\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "60de8da7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference NODE"
   ],
   "id": "390276e5"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from experiments.exp3a_plots import train_model, plot_dynamics\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "func_ref = TimeDepODE_ELU(hidden_dim=CFG[\"hidden_dim\"])\n",
    "losses_ref, time_ref = train_model(func_ref, X_train, y_train, t_train, CFG)\n",
    "print(f\"Training time: {time_ref:.1f}s, final loss: {losses_ref[-1]:.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_ref = odeint(func_ref, X_train, t_eval, method=\"rk4\",\n",
    "                   options={\"step_size\": step_eval})\n",
    "print(f\"Train acc: {compute_accuracy(y_ref[-1], y_train):.2%}\")\n",
    "\n",
    "plot_dynamics(y_ref, y_train, \"NODE\", OUT, \"ex3a_node_dynamics\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "0d3114fb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM ensemble"
   ],
   "id": "37cc20f8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from experiments.exp3a_plots import train_rbm_ensemble\n",
    "\n",
    "print(f\"Training RBM ensemble ({CFG['n_batches']} batches, K={CFG['n_realizations']})...\")\n",
    "rbm = train_rbm_ensemble(X_train, y_train, t_train, t_eval, CFG)\n",
    "print(f\"Avg time/realisation: {rbm['avg_time']:.1f}s\")\n",
    "\n",
    "acc_rbm = compute_accuracy(rbm[\"y_avg\"][-1], y_train)\n",
    "print(f\"Ensemble train acc: {acc_rbm:.2%}\")\n",
    "\n",
    "plot_dynamics(rbm[\"y_avg\"], y_train, \"rNODE\", OUT, \"ex3a_rnode_dynamics\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "0d3114fb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundaries"
   ],
   "id": "122ce879"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from experiments.exp3a_plots import plot_decision_boundaries\n",
    "from rnode.data import make_grid\n",
    "\n",
    "n_grid = CFG[\"n_grid\"]\n",
    "xx, yy, grid = make_grid(n_points=n_grid)\n",
    "\n",
    "boundaries, accuracies = {}, {}\n",
    "\n",
    "# Reference\n",
    "print(\"Computing NODE boundary...\")\n",
    "with torch.no_grad():\n",
    "    y_g = odeint(func_ref, grid, t_eval, method=\"rk4\",\n",
    "                 options={\"step_size\": step_eval})\n",
    "boundaries[\"NODE\"] = y_g[-1, :, 0].numpy()\n",
    "with torch.no_grad():\n",
    "    y_te = odeint(func_ref, X_test, t_eval, method=\"rk4\",\n",
    "                  options={\"step_size\": step_eval})\n",
    "accuracies[\"NODE\"] = compute_accuracy(y_te[-1], y_test)\n",
    "\n",
    "# rNODE at different h\n",
    "for rep in CFG[\"h_reps\"]:\n",
    "    print(f\"Computing rNODE boundary (h={rep}*dt)...\")\n",
    "    cfg_bnd = {**CFG, \"n_realizations\": CFG[\"n_real_boundary\"]}\n",
    "    rbm_h = train_rbm_ensemble(X_train, y_train, t_train, t_eval,\n",
    "                                cfg_bnd, rep=rep, verbose=False)\n",
    "    grid_preds, test_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for m in rbm_h[\"models\"]:\n",
    "            grid_preds.append(odeint(m, grid, t_eval, method=\"rk4\",\n",
    "                                     options={\"step_size\": step_eval})[-1, :, 0])\n",
    "            test_preds.append(odeint(m, X_test, t_eval, method=\"rk4\",\n",
    "                                     options={\"step_size\": step_eval})[-1])\n",
    "    boundaries[f\"h={rep}\"] = torch.mean(torch.stack(grid_preds), 0).numpy()\n",
    "    accuracies[f\"h={rep}\"] = compute_accuracy(\n",
    "        torch.mean(torch.stack(test_preds), 0), y_test)\n",
    "    print(f\"  acc = {accuracies[f'h={rep}']:.2%}\")\n",
    "\n",
    "plot_decision_boundaries(boundaries, accuracies, xx, yy,\n",
    "                         X_test, y_test, OUT, \"ex3a_decision_boundaries\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "0d3114fb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ],
   "id": "14545670"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from experiments.exp3a_plots import plot_benchmark_table\n",
    "\n",
    "# This cell takes a long time \u2014 skip with QUICK\n",
    "benchmark_results = {}\n",
    "\n",
    "print(\"Benchmarking NODE...\")\n",
    "from experiments.exp3a_plots import train_model as tm3a\n",
    "node_trials = []\n",
    "for trial in range(CFG[\"n_benchmark_trials\"]):\n",
    "    torch.manual_seed(SEED + trial)\n",
    "    model = TimeDepODE_ELU(CFG[\"hidden_dim\"])\n",
    "    losses, elapsed = tm3a(model, X_train, y_train, t_train, CFG, verbose=False)\n",
    "    with torch.no_grad():\n",
    "        y_tr = odeint(model, X_train, t_eval, method=\"rk4\",\n",
    "                      options={\"step_size\": step_eval})\n",
    "        y_te = odeint(model, X_test, t_eval, method=\"rk4\",\n",
    "                      options={\"step_size\": step_eval})\n",
    "    node_trials.append({\"time\": elapsed, \"loss\": losses[-1],\n",
    "                         \"train_acc\": compute_accuracy(y_tr[-1], y_train),\n",
    "                         \"test_acc\": compute_accuracy(y_te[-1], y_test)})\n",
    "benchmark_results[\"NODE\"] = {\n",
    "    \"train_acc_mean\": np.mean([t[\"train_acc\"] for t in node_trials]),\n",
    "    \"test_acc_mean\": np.mean([t[\"test_acc\"] for t in node_trials]),\n",
    "    \"time_mean\": np.mean([t[\"time\"] for t in node_trials]),\n",
    "}\n",
    "print(f\"  test={benchmark_results['NODE']['test_acc_mean']:.2%}\")\n",
    "\n",
    "for nb in CFG[\"batch_configs\"]:\n",
    "    print(f\"Benchmarking RBM ({nb} batches)...\")\n",
    "    cfg_b = {**CFG, \"n_batches\": nb, \"n_realizations\": CFG[\"n_realizations_bench\"]}\n",
    "    trials = []\n",
    "    for trial in range(CFG[\"n_benchmark_trials\"]):\n",
    "        rbm_b = train_rbm_ensemble(X_train, y_train, t_train, t_eval,\n",
    "                                    cfg_b, verbose=False)\n",
    "        with torch.no_grad():\n",
    "            te_preds = [odeint(m, X_test, t_eval, method=\"rk4\",\n",
    "                               options={\"step_size\": step_eval})[-1]\n",
    "                        for m in rbm_b[\"models\"]]\n",
    "            tr_preds = [odeint(m, X_train, t_eval, method=\"rk4\",\n",
    "                               options={\"step_size\": step_eval})[-1]\n",
    "                        for m in rbm_b[\"models\"]]\n",
    "        trials.append({\n",
    "            \"train_acc\": compute_accuracy(torch.mean(torch.stack(tr_preds), 0), y_train),\n",
    "            \"test_acc\": compute_accuracy(torch.mean(torch.stack(te_preds), 0), y_test),\n",
    "            \"time\": rbm_b[\"avg_time\"],\n",
    "        })\n",
    "    benchmark_results[f\"{nb}_batches\"] = {\n",
    "        \"train_acc_mean\": np.mean([t[\"train_acc\"] for t in trials]),\n",
    "        \"test_acc_mean\": np.mean([t[\"test_acc\"] for t in trials]),\n",
    "        \"time_mean\": np.mean([t[\"time\"] for t in trials]),\n",
    "    }\n",
    "    print(f\"  test={benchmark_results[f'{nb}_batches']['test_acc_mean']:.2%}\")\n",
    "\n",
    "plot_benchmark_table(benchmark_results, CFG[\"batch_configs\"], OUT, \"ex3a_benchmark\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "0d3114fb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ],
   "id": "598ab214"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "torch.save(func_ref.state_dict(), os.path.join(OUT, \"ex3a_node.pth\"))\n",
    "print(\"Done.\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "700c7d8a"
  }
 ]
}
